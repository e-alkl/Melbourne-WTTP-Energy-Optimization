import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import shap
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import joblib

# --- æª”æ¡ˆèˆ‡æ¬„ä½å®šç¾© (ETP æ•¸æ“š) ---
INPUT_FILE = 'melbourne_etp_optimized_training_data.csv' 
TARGET_COL = 'Energy Consumption' # ç¸½èƒ½è€—ï¼Œè¿´æ­¸ç›®æ¨™

# é å…ˆå®šç¾©è¼¸å…¥ç‰¹å¾µ (X)
# æ’é™¤ç›®æ¨™å’Œå‰µå»ºçš„ Pass æ¨™ç±¤ï¼Œä»¥åŠæ°´è³ªæŒ‡æ¨™æœ¬èº«ï¼ˆå®ƒå€‘æ˜¯ç´„æŸæ¢ä»¶ï¼‰
EXCLUDE_COLS = [
    TARGET_COL, 'Quality_Pass', 'BOD_Pass', 'COD_Pass', 
    'Biological Oxygen Demand', 'Chemical Oxygen Demand'
]

print("--- å°ˆæ¡ˆ 3ï¼šå¢¨çˆ¾æœ¬ ETP èƒ½è€—å„ªåŒ– (XGBoost è¿´æ­¸) ---")

try:
    # 1. è¼‰å…¥å„ªåŒ–å¾Œçš„æ•¸æ“šé›†
    df = pd.read_csv(INPUT_FILE, index_col=0)
    
    # 2. å®šç¾© X å’Œ Y
    X_features = [col for col in df.columns if col not in EXCLUDE_COLS]
    
    X = df[X_features].astype(float)
    Y = df[TARGET_COL].astype(float)

    print(f"æ¨¡å‹å°‡ä½¿ç”¨ {len(X_features)} å€‹ç‰¹å¾µé€²è¡Œè¨“ç·´: {X_features}")

    # 3. åŠƒåˆ†è¨“ç·´é›†å’Œæ¸¬è©¦é›† (90/10)
    X_train, X_test, Y_train, Y_test = train_test_split(
        X, Y, test_size=0.1, random_state=42
    )

    # 4. è¨“ç·´ XGBoost è¿´æ­¸æ¨¡å‹ (èª¿æ•´åƒæ•¸ä»¥é©æ‡‰å°æ¨£æœ¬)
    regressor = XGBRegressor(
        objective='reg:squarederror', 
        n_estimators=100, 
        learning_rate=0.1, 
        max_depth=3, 
        random_state=42,
        n_jobs=-1
    )
    
    print("â³ é–‹å§‹è¨“ç·´ XGBoost è¿´æ­¸æ¨¡å‹...")
    regressor.fit(X_train, Y_train)
    print("âœ… æ¨¡å‹è¨“ç·´å®Œæˆï¼")

    # 5. æ¨¡å‹é æ¸¬èˆ‡è©•ä¼°
    Y_pred = regressor.predict(X_test)
    
    # ä½¿ç”¨ np.sqrt æ‰‹å‹•è¨ˆç®— RMSE
    rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))
    # ä½¿ç”¨ np.mean æ‰‹å‹•è¨ˆç®— MAE
    mae = np.mean(np.abs(Y_test - Y_pred)) 

    print("\n--- æ¨¡å‹æ€§èƒ½è©•ä¼° (ç›®æ¨™: ç¸½èƒ½è€— kWh) ---")
    print(f"RMSE (å‡æ–¹æ ¹èª¤å·®): {rmse:.2f} kWh")
    print(f"MAE (å¹³å‡çµ•å°èª¤å·®): {mae:.2f} kWh")
    print(f"å¹³å‡èƒ½è€—: {Y_test.mean():.2f} kWh")
    print(f"MAE ä½”å¹³å‡èƒ½è€—çš„ç™¾åˆ†æ¯”: {(mae / Y_test.mean() * 100):.2f}%")
    
    # 6. SHAP å¯è§£é‡‹æ€§åˆ†æ
    explainer = shap.TreeExplainer(regressor)
    shap_values = explainer.shap_values(X_test)

    # æ‰¾å‡ºä¸¦æ‰“å°å‰ä¸‰å€‹é‡è¦ç‰¹å¾µ
    feature_importance = pd.Series(np.abs(shap_values).mean(axis=0), index=X_test.columns)
    top_3_features = feature_importance.nlargest(3)

    print("\n--- å‰ 3 å€‹æœ€é‡è¦çš„èƒ½è€—å½±éŸ¿ç‰¹å¾µ (SHAP å€¼) ---")
    for name, value in top_3_features.items():
        print(f"  - {name}: {value:.2f}")

    # 7. ç¹ªè£½ SHAP æ‘˜è¦åœ–
    print("ç”Ÿæˆ SHAP æ‘˜è¦åœ–ï¼Œè«‹æŸ¥çœ‹é¡¯ç¤ºè¦–çª—...")
    shap.summary_plot(shap_values, X_test, show=True)
    plt.title("SHAP Feature Importance for ETP Energy Prediction (Optimized Data)")
    plt.tight_layout()

except FileNotFoundError:
    print(f"ğŸš¨ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {INPUT_FILE}ã€‚è«‹ç¢ºä¿æ‚¨å·²æˆåŠŸé‹è¡Œæ•¸æ“šæº–å‚™è…³æœ¬ã€‚")
except Exception as e:
    print(f"ğŸš¨ é‹è¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    import joblib 

# å„²å­˜è¨“ç·´å¥½çš„ XGBoost æ¨¡å‹
MODEL_FILE = 'etp_energy_model.joblib'
joblib.dump(regressor, MODEL_FILE)
print(f"âœ… æ¨¡å‹å·²å„²å­˜è‡³ï¼š{MODEL_FILE}")

# å„²å­˜ç‰¹å¾µåˆ—è¡¨ (ç¢ºä¿ Web App ä½¿ç”¨ç›¸åŒçš„é †åº)
FEATURE_LIST_FILE = 'etp_features.joblib'
joblib.dump(X_features, FEATURE_LIST_FILE)
print(f"âœ… ç‰¹å¾µåˆ—è¡¨å·²å„²å­˜è‡³ï¼š{FEATURE_LIST_FILE}")